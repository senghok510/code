{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name entity recognition \n",
    "\n",
    "# Author: Hok Seng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Notebook Sections</b><br>\n",
    "    This notebook is divided into the following sections:\n",
    "    <ul>\n",
    "        <li>A. Setting Environment</li>\n",
    "        <li>B. Set the Devic (cpu or mps) </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/senghok/Documents/Internship 2A/code'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import logging\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"requirement.txt\", \"r\") as file:\n",
    "#     for f in file.readlines():\n",
    "#         package = f.strip()\n",
    "#         if package:\n",
    "#             subprocess.check_call([\"pip\", \"install\", package])\n",
    "#             %pip install {package}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save_dir = \"data\"\n",
    "# os.makedirs(save_dir,exist_ok = True)\n",
    "\n",
    "# file_name = os.path.join(save_dir,\"NER_dataset.csv\")\n",
    "\n",
    "# response = requests.get(url,stream = True)\n",
    "\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     with open(file_name,\"wb\") as file:\n",
    "#         for chunk in response.iter_content(chunk_size=1024):\n",
    "#             file.write(chunk)\n",
    "#     print(f\"File downloaded successfully and saved to {file_name}\")\n",
    "# else:\n",
    "#     print(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/senghok/Documents/Internship 2A/code/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from itertools import chain\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForTokenClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import LSTM\n",
    "\n",
    "\n",
    "# set the option to display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "valid_df = pd.read_csv('./data/valid.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset size: 34279\n",
      "Valid Data Size: 3808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Train Dataset size: {len(train_df)}\")\n",
    "print(f\"Valid Data Size: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (34279, 2)\n",
      "VALID Dataset: (3808, 2)\n",
      "TEST Dataset: (9520, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"VALID Dataset: {}\".format(valid_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The party is divided over Britain 's participa...</td>\n",
       "      <td>O,O,O,O,O,B-gpe,O,O,O,O,B-geo,O,O,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two Germans and four Nigerian oil workers were...</td>\n",
       "      <td>O,B-gpe,O,O,B-gpe,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The German firm works as a sub-contractor for ...</td>\n",
       "      <td>O,B-gpe,O,O,O,O,O,O,B-org,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Families of soldiers killed in the conflict jo...   \n",
       "1  Police put the number of marchers at 10,000 wh...   \n",
       "2  The party is divided over Britain 's participa...   \n",
       "3  Two Germans and four Nigerian oil workers were...   \n",
       "4  The German firm works as a sub-contractor for ...   \n",
       "\n",
       "                                              labels  \n",
       "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...  \n",
       "1                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "2  O,O,O,O,O,B-gpe,O,O,O,O,B-geo,O,O,O,O,O,O,O,B-...  \n",
       "3  O,B-gpe,O,O,B-gpe,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4                        O,B-gpe,O,O,O,O,O,O,B-org,O  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O,B-gpe,O,O,B-gpe,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,O,B-geo,O,O'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"labels\"].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Two Germans and four Nigerian oil workers were kidnapped by armed militants during a raid on a boat in Nigeria 's southern oil-rich Delta region .\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"sentence\"].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The party is divided over Britain 's participa...</td>\n",
       "      <td>O,O,O,O,O,B-gpe,O,O,O,O,B-geo,O,O,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Families of soldiers killed in the conflict jo...   \n",
       "1  Police put the number of marchers at 10,000 wh...   \n",
       "2  The party is divided over Britain 's participa...   \n",
       "\n",
       "                                              labels  \n",
       "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...  \n",
       "1                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "2  O,O,O,O,O,B-gpe,O,O,O,O,B-geo,O,O,O,O,O,O,O,B-...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-geo',\n",
       " 'B-gpe',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-geo',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = train_df['labels'].apply(lambda x: x.split(','))\n",
    "all_labels = sorted(set(label for labels in all_labels for label in labels ))\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding for all the labels in training , validation and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Initialize the MultiLabelBinarizer with all known classes\n",
    "mlb = MultiLabelBinarizer(classes=sorted(all_labels))\n",
    "# Step 3: Transform per-sentence label sets\n",
    "unique_train_labels_ohe = mlb.fit_transform(\n",
    "    train_df['labels'].apply(lambda x: set(x.split(',')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34279, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_train_labels_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Validation\n",
    "unique_valid_labels_ohe = mlb.transform(\n",
    "    valid_df['labels'].apply(lambda x: set(x.split(',')))\n",
    ")\n",
    "\n",
    "# Testing\n",
    "unique_test_labels_ohe = mlb.transform(\n",
    "    test_df['labels'].apply(lambda x: set(x.split(',')))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_valid_labels_ohe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# compute number of samples\u001b[39;00m\n\u001b[32m      2\u001b[39m num_train_samples = unique_train_labels_ohe.shape[\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m num_valid_samples = \u001b[43munique_valid_labels_ohe\u001b[49m.shape[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m num_test_samples = unique_test_labels_ohe.shape[\u001b[32m0\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# compute number of samples for each unique label\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'unique_valid_labels_ohe' is not defined"
     ]
    }
   ],
   "source": [
    "# compute number of samples\n",
    "num_train_samples = unique_train_labels_ohe.shape[0]\n",
    "num_valid_samples = unique_valid_labels_ohe.shape[0]\n",
    "num_test_samples = unique_test_labels_ohe.shape[0]\n",
    "\n",
    "# compute number of samples for each unique label\n",
    "train_labels_count = unique_train_labels_ohe.sum(axis=0)\n",
    "valid_labels_count = unique_valid_labels_ohe.sum(axis=0)\n",
    "test_labels_count = unique_test_labels_ohe.sum(axis=0)\n",
    "\n",
    "# compute proportion of samples for each unique label\n",
    "prop_train_labels = train_labels_count/num_train_samples\n",
    "prop_valid_labels = valid_labels_count/num_valid_samples\n",
    "prop_test_labels = test_labels_count/num_test_samples\n",
    "\n",
    "\n",
    "print(\"Training Data\")\n",
    "print(\"==============\")\n",
    "print(f\"Total num of training samples: {num_train_samples}\")\n",
    "print(f\"Total num of each label: {train_labels_count}\")\n",
    "print(f\"Proportions of each label: {prop_train_labels}\\n\")\n",
    "\n",
    "print(\"Validation Data\")\n",
    "print(\"==============\")\n",
    "print(f\"Total num of validation samples: {num_valid_samples}\")\n",
    "print(f\"Total num of each label: {valid_labels_count}\")\n",
    "print(f\"Proportions of each label: {prop_valid_labels}\\n\")\n",
    "\n",
    "print(\"Testing Data\")\n",
    "print(\"===============\")\n",
    "print(f\"Total num of training samples: {num_test_samples}\")\n",
    "print(f\"Total num of each label: {test_labels_count}\")\n",
    "print(f\"Proportions of each label: {prop_test_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the proportion dataFrame for training, validation and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {k:v+1 for v,k in enumerate(all_labels)}\n",
    "id2label = {k+1:v for k,v in enumerate(all_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict for proportions of each label\n",
    "prop_data = {\n",
    "    'labels' : list(label2id.keys()),\n",
    "    'train' : prop_train_labels,\n",
    "    'valid' : prop_valid_labels,\n",
    "    'test' : prop_test_labels\n",
    "}\n",
    "\n",
    "\n",
    "prop_df = pd.DataFrame.from_dict(prop_data)\n",
    "\n",
    "\n",
    "display(prop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# g = sns.barplot(\n",
    "#     data=prop_df.melt(id_vars = [\"labels\"], value_vars=[\"train\", \"valid\", \"test\"]),\n",
    "#     y=\"value\", x=\"v\n",
    "# \n",
    "# \n",
    "# \n",
    "# ariable\", hue=\"labels\", errorbar=None\n",
    "# )\n",
    "\n",
    "# # for legend text\n",
    "# plt.setp(g.get_legend().get_texts(), fontsize='10')  \n",
    " \n",
    "# # for legend title\n",
    "# plt.setp(g.get_legend().get_title(), fontsize='10')\n",
    "# plt.title(\"Proportions of sentences containing each label - training, validation and testing dataset\")\n",
    "# plt.savefig('./images/label_proportions.png', bbox_inches='tight', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distributions of 2nd order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "\n",
    "# label_combination_df = pd.DataFrame({\n",
    "#     'train': Counter(str(combination) for row in get_combination_wise_output_matrix(unique_train_labels_ohe, order=2) for combination in row),\n",
    "#     'valid': Counter(str(combination) for row in get_combination_wise_output_matrix(unique_valid_labels_ohe, order=2) for combination in row),\n",
    "#     'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(unique_test_labels_ohe, order=2) for combination in row),\n",
    "# }).T.fillna(0.0).astype('float')\n",
    "\n",
    "# # compute proportions\n",
    "# label_combination_df.loc['train'] = label_combination_df.loc['train']/num_train_samples\n",
    "# label_combination_df.loc['valid'] = label_combination_df.loc['valid']/num_valid_samples\n",
    "# label_combination_df.loc['test'] = label_combination_df.loc['test']/num_test_samples\n",
    "\n",
    "# label_combination_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "\n",
    "# label_combination_df = pd.DataFrame({\n",
    "#     'train': Counter(str(combination) for row in get_combination_wise_output_matrix(unique_train_labels_ohe, order=3) for combination in row),\n",
    "#     'valid': Counter(str(combination) for row in get_combination_wise_output_matrix(unique_valid_labels_ohe, order=3) for combination in row),\n",
    "#     'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(unique_test_labels_ohe, order=3) for combination in row),\n",
    "# }).T.fillna(0.0).astype('float')\n",
    "\n",
    "# # compute proportions\n",
    "# label_combination_df.loc['train'] = label_combination_df.loc['train']/num_train_samples\n",
    "# label_combination_df.loc['valid'] = label_combination_df.loc['valid']/num_valid_samples\n",
    "# label_combination_df.loc['test'] = label_combination_df.loc['test']/num_test_samples\n",
    "\n",
    "# label_combination_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "### RNN + Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "There are many tokenization methods  including:\n",
    "<li>\n",
    "Bert Tokenizer \n",
    "</li>\n",
    "<li>\n",
    "Byte-Pair Encoding (BPE) - Robust to unknown words\n",
    "</li>\n",
    "\n",
    "### Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences (whitespace)\n",
    "def tokenize(sentence):\n",
    "    return sentence.strip().split()\n",
    "# Split labels\n",
    "def split_labels(label_str):\n",
    "    return label_str.strip().split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['tokens'] = train_df['sentence'].apply(tokenize)\n",
    "train_df['label_list'] = train_df['labels'].apply(split_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>The visit by Assistant Secretary of State for ...</td>\n",
       "      <td>O,O,O,O,O,O,B-org,I-org,I-org,I-org,I-org,I-or...</td>\n",
       "      <td>[The, visit, by, Assistant, Secretary, of, Sta...</td>\n",
       "      <td>[O, O, O, O, O, O, B-org, I-org, I-org, I-org,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Strong performances in construction and manufa...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "      <td>[Strong, performances, in, construction, and, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>After failing in the Korean War ( 1950 - 53 ) ...</td>\n",
       "      <td>O,O,O,O,O,O,O,B-tim,I-tim,I-tim,O,O,O,O,B-geo,...</td>\n",
       "      <td>[After, failing, in, the, Korean, War, (, 1950...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-tim, I-tim, I-tim, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>Former U.S. Marine General John J. \" Jack \" Sh...</td>\n",
       "      <td>O,B-org,I-org,I-org,B-per,I-per,I-per,I-per,I-...</td>\n",
       "      <td>[Former, U.S., Marine, General, John, J., \", J...</td>\n",
       "      <td>[O, B-org, I-org, I-org, B-per, I-per, I-per, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>But the Honest Man explained that as he was me...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "      <td>[But, the, Honest, Man, explained, that, as, h...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30696</th>\n",
       "      <td>Mourners and officials of the Socialist Party ...</td>\n",
       "      <td>O,O,O,O,O,B-org,I-org,O,O,B-per,O,O,O,O,O,O,O,...</td>\n",
       "      <td>[Mourners, and, officials, of, the, Socialist,...</td>\n",
       "      <td>[O, O, O, O, O, B-org, I-org, O, O, B-per, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796</th>\n",
       "      <td>In an interview broadcast Sunday on U.S. telev...</td>\n",
       "      <td>O,O,O,O,B-tim,O,B-geo,O,O,O,B-org,O,O,O,O,O,B-...</td>\n",
       "      <td>[In, an, interview, broadcast, Sunday, on, U.S...</td>\n",
       "      <td>[O, O, O, O, B-tim, O, B-geo, O, O, O, B-org, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32287</th>\n",
       "      <td>Following its heyday as a global maritime powe...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,B-tim,I-tim,I-tim,O,O,B-pe...</td>\n",
       "      <td>[Following, its, heyday, as, a, global, mariti...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-tim, I-tim, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32874</th>\n",
       "      <td>Renewed activity in the mining sector , the so...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,O,O,O,...</td>\n",
       "      <td>[Renewed, activity, in, the, mining, sector, ,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34145</th>\n",
       "      <td>Two federal policemen walk past crosses standi...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-tim,O,B-ge...</td>\n",
       "      <td>[Two, federal, policemen, walk, past, crosses,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "600    The visit by Assistant Secretary of State for ...   \n",
       "635    Strong performances in construction and manufa...   \n",
       "803    After failing in the Korean War ( 1950 - 53 ) ...   \n",
       "1140   Former U.S. Marine General John J. \" Jack \" Sh...   \n",
       "4348   But the Honest Man explained that as he was me...   \n",
       "...                                                  ...   \n",
       "30696  Mourners and officials of the Socialist Party ...   \n",
       "30796  In an interview broadcast Sunday on U.S. telev...   \n",
       "32287  Following its heyday as a global maritime powe...   \n",
       "32874  Renewed activity in the mining sector , the so...   \n",
       "34145  Two federal policemen walk past crosses standi...   \n",
       "\n",
       "                                                  labels  \\\n",
       "600    O,O,O,O,O,O,B-org,I-org,I-org,I-org,I-org,I-or...   \n",
       "635    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...   \n",
       "803    O,O,O,O,O,O,O,B-tim,I-tim,I-tim,O,O,O,O,B-geo,...   \n",
       "1140   O,B-org,I-org,I-org,B-per,I-per,I-per,I-per,I-...   \n",
       "4348   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...   \n",
       "...                                                  ...   \n",
       "30696  O,O,O,O,O,B-org,I-org,O,O,B-per,O,O,O,O,O,O,O,...   \n",
       "30796  O,O,O,O,B-tim,O,B-geo,O,O,O,B-org,O,O,O,O,O,B-...   \n",
       "32287  O,O,O,O,O,O,O,O,O,O,B-tim,I-tim,I-tim,O,O,B-pe...   \n",
       "32874  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,O,O,O,...   \n",
       "34145  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-tim,O,B-ge...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "600    [The, visit, by, Assistant, Secretary, of, Sta...   \n",
       "635    [Strong, performances, in, construction, and, ...   \n",
       "803    [After, failing, in, the, Korean, War, (, 1950...   \n",
       "1140   [Former, U.S., Marine, General, John, J., \", J...   \n",
       "4348   [But, the, Honest, Man, explained, that, as, h...   \n",
       "...                                                  ...   \n",
       "30696  [Mourners, and, officials, of, the, Socialist,...   \n",
       "30796  [In, an, interview, broadcast, Sunday, on, U.S...   \n",
       "32287  [Following, its, heyday, as, a, global, mariti...   \n",
       "32874  [Renewed, activity, in, the, mining, sector, ,...   \n",
       "34145  [Two, federal, policemen, walk, past, crosses,...   \n",
       "\n",
       "                                              label_list  \n",
       "600    [O, O, O, O, O, O, B-org, I-org, I-org, I-org,...  \n",
       "635    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "803    [O, O, O, O, O, O, O, B-tim, I-tim, I-tim, O, ...  \n",
       "1140   [O, B-org, I-org, I-org, B-per, I-per, I-per, ...  \n",
       "4348   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                  ...  \n",
       "30696  [O, O, O, O, O, B-org, I-org, O, O, B-per, O, ...  \n",
       "30796  [O, O, O, O, B-tim, O, B-geo, O, O, O, B-org, ...  \n",
       "32287  [O, O, O, O, O, O, O, O, O, O, B-tim, I-tim, I...  \n",
       "32874  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "34145  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[74 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"tokens\"].apply(len) >50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use Text vectorization\n",
    "\n",
    "# Text vectorization consiste of parts:\n",
    "<li>\n",
    "    Standardization\n",
    "</li>\n",
    "<li>\n",
    "    Tokenization\n",
    "</li>\n",
    "<li>\n",
    "    Vocabulary building\n",
    "</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary dictionaries for encoding and decoding phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label2id = {k:v+1 for v,k in enumerate(all_labels)}\n",
    "id2label = {k+1:v for k,v in enumerate(all_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id[\"<PAD>\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-org': 3,\n",
       " 'B-per': 4,\n",
       " 'B-tim': 5,\n",
       " 'I-geo': 6,\n",
       " 'I-org': 7,\n",
       " 'I-per': 8,\n",
       " 'I-tim': 9,\n",
       " 'O': 10,\n",
       " '<PAD>': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(word for tokens in train_df['tokens'] for word in tokens)\n",
    "word2id = {word: i + 2 for i, word in enumerate(word_counts)} # turn words into unique ids (+2) because give 0,1 to UNK and PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i+2:word for i,word in enumerate(word_counts)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add '<PAD>' to use when padding and '<UNK>' in the case where there are unknown entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id['<PAD>'] = 0\n",
    "word2id['<UNK>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fallback = '<UNK>'\n",
    "fallback_id = word2id.get('B-gpe', list(label2id.values())[0])  ## get idea of a word\n",
    "\n",
    "fallback_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token = '<PAD>'\n",
    "pad_id = label2id.get(pad_token, list(label2id.values())[0])  \n",
    "pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 40\n",
    "\n",
    "def encode(tokens, vocab, pad_len=40, fallback='<UNK>', pad_token='<PAD>'):\n",
    "    \"\"\"\n",
    "    Encodes a list of tokens using a vocabulary.\n",
    "\n",
    "    - tokens: List[str] → tokens or labels (e.g., words or NER tags)\n",
    "    - vocab: dict → maps token to index\n",
    "    - pad_len: int → fixed output length (pad or truncate)\n",
    "    - fallback: str → token to use if one isn't found (only relevant for input)\n",
    "    - pad_token: str → token to use for padding\n",
    "\n",
    "    Returns: List[int] of length `pad_len`\n",
    "    \"\"\"\n",
    "    fallback_id = vocab.get(fallback, 0)     # Use <UNK> if token not found\n",
    "    pad_id = vocab.get(pad_token, 0)         # Use <PAD> for padding\n",
    "\n",
    "    # Map each token to its ID\n",
    "    ids = [vocab.get(tok, fallback_id) for tok in tokens]\n",
    "\n",
    "    # Truncate or pad to fixed length\n",
    "    if len(ids) > pad_len:\n",
    "        return ids[:pad_len]\n",
    "    else:\n",
    "        return ids + [pad_id] * (pad_len - len(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([encode(tokens, word2id, fallback='<UNK>', pad_token='<PAD>') for tokens in train_df['tokens']])\n",
    "y = np.array([encode(labels, label2id, fallback='O', pad_token= '<PAD>') for labels in train_df['label_list']])\n",
    "vocab_size = len(word2id)\n",
    "label_size = len(label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9,  7, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 18, 23, 18, 24,  7, 25, 26, 18,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : ['The', 'party', 'is', 'divided', 'over', 'Britain', \"'s\", 'participation', 'in', 'the', 'Iraq', 'conflict', 'and', 'the', 'continued', 'deployment', 'of', '8,500', 'British', 'troops', 'in', 'that', 'country', '.'] with length 24\n",
      " encoded sentence : [39, 40, 41, 42, 43, 44, 45, 46, 6, 7, 47, 8, 23, 7, 48, 49, 3, 50, 51, 52, 6, 53, 54, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] with length 40\n",
      "\n",
      "Label : ['O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O'] with length 24\n",
      " encoded label : [10, 10, 10, 10, 10, 2, 10, 10, 10, 10, 1, 10, 10, 10, 10, 10, 10, 10, 2, 10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] with length 40\n"
     ]
    }
   ],
   "source": [
    "## Example:\n",
    "sentence = train_df['tokens'][2]   \n",
    "label    = train_df['label_list'][2]\n",
    "encoded_sentence = encode(sentence,word2id,fallback= '<UNK>', pad_token = '<PAD>')\n",
    "encoded_label  = encode(label, label2id, fallback = 'O', pad_token = '<PAD>')\n",
    "print(f\"Sentence : {sentence} with length {len(sentence)}\\n\",\n",
    "       f\"encoded sentence : {encoded_sentence} with length {len(encoded_sentence)}\\n\")\n",
    "\n",
    "print(f\"Label : {label} with length {len(label)}\\n\",\n",
    "       f\"encoded label : {encoded_label} with length {len(encoded_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'party',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'over',\n",
       " 'Britain',\n",
       " \"'s\",\n",
       " 'participation',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Iraq',\n",
       " 'conflict',\n",
       " 'and',\n",
       " 'the',\n",
       " 'continued',\n",
       " 'deployment',\n",
       " 'of',\n",
       " '8,500',\n",
       " 'British',\n",
       " 'troops',\n",
       " 'in',\n",
       " 'that',\n",
       " 'country',\n",
       " '.',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " '<UNK>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "id2word = {v:k for k,v in word2id.items()}\n",
    "# Decode the sentence\n",
    "decoded_sentence = [id2word.get(word_id, '<UNK>') for word_id in encoded_sentence]\n",
    "decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'party',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'over',\n",
       " 'B-gpe',\n",
       " \"'s\",\n",
       " 'participation',\n",
       " 'in',\n",
       " 'the',\n",
       " 'B-geo',\n",
       " 'conflict',\n",
       " 'and',\n",
       " 'the',\n",
       " 'continued',\n",
       " 'deployment',\n",
       " 'of',\n",
       " '8,500',\n",
       " 'B-gpe',\n",
       " 'troops',\n",
       " 'in',\n",
       " 'that',\n",
       " 'country',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to sentence with masked entity\n",
    "sentence_masked = []\n",
    "for index, lab in enumerate(label):\n",
    "    if lab == 'O':\n",
    "        sentence_masked.append(sentence[index])\n",
    "    else:\n",
    "        sentence_masked.append(label[index])\n",
    "sentence_masked       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (34279, 40), y shape: (34279, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30523, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size,label_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The International Atomic Energy Agency is to h...</td>\n",
       "      <td>O,B-org,I-org,I-org,I-org,O,O,O,O,O,O,O,O,B-ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The European Union , with U.S. backing , has t...</td>\n",
       "      <td>O,B-org,I-org,O,O,B-gpe,O,O,O,O,O,O,B-gpe,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Militant groups frequently attack oil operatio...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,B-geo,I-geo,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The attacks occurred after the government said...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-gpe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>Aircraft also struck a building allegedly used...</td>\n",
       "      <td>B-org,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>One Hamas militant was reported killed and two...</td>\n",
       "      <td>O,B-org,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>Media reports say Ford will cut 25,000 or more...</td>\n",
       "      <td>O,O,O,B-org,O,O,O,O,O,O,O,O,O,B-tim,I-tim,I-ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>The powerful Muslim Brotherhood Movement based...</td>\n",
       "      <td>O,O,B-org,I-org,I-org,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>The United Nations and African Union are in th...</td>\n",
       "      <td>O,B-org,I-org,I-org,I-org,I-org,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3808 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     They marched from the Houses of Parliament to ...   \n",
       "1     The International Atomic Energy Agency is to h...   \n",
       "2     The European Union , with U.S. backing , has t...   \n",
       "3     Militant groups frequently attack oil operatio...   \n",
       "4     The attacks occurred after the government said...   \n",
       "...                                                 ...   \n",
       "3803  Aircraft also struck a building allegedly used...   \n",
       "3804  One Hamas militant was reported killed and two...   \n",
       "3805  Media reports say Ford will cut 25,000 or more...   \n",
       "3806  The powerful Muslim Brotherhood Movement based...   \n",
       "3807  The United Nations and African Union are in th...   \n",
       "\n",
       "                                                 labels  \n",
       "0                   O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O  \n",
       "1     O,B-org,I-org,I-org,I-org,O,O,O,O,O,O,O,O,B-ge...  \n",
       "2     O,B-org,I-org,O,O,B-gpe,O,O,O,O,O,O,B-gpe,O,O,...  \n",
       "3     O,O,O,O,O,O,O,O,B-geo,I-geo,O,O,O,O,O,O,O,O,O,...  \n",
       "4     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-gpe,...  \n",
       "...                                                 ...  \n",
       "3803                      B-org,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "3804                        O,B-org,O,O,O,O,O,O,O,O,O,O  \n",
       "3805  O,O,O,B-org,O,O,O,O,O,O,O,O,O,B-tim,I-tim,I-ti...  \n",
       "3806  O,O,B-org,I-org,I-org,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3807  O,B-org,I-org,I-org,I-org,I-org,O,O,O,O,O,O,O,...  \n",
       "\n",
       "[3808 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences and split labels\n",
    "for df in [valid_df, test_df]:\n",
    "    df['tokens'] = df['sentence'].apply(lambda x: x.strip().split())\n",
    "    df['label_list'] = df['labels'].apply(lambda x: x.strip().split(','))\n",
    "X_valid = np.array([\n",
    "    encode(tokens, word2id, fallback='<UNK>', pad_token='<PAD>')\n",
    "    for tokens in valid_df['tokens']\n",
    "])\n",
    "\n",
    "y_valid = np.array([\n",
    "    encode(labels, label2id, fallback='O', pad_token='O')\n",
    "    for labels in valid_df['label_list']\n",
    "])\n",
    "X_test = np.array([\n",
    "    encode(tokens, word2id, fallback='<UNK>', pad_token='<PAD>')\n",
    "    for tokens in test_df['tokens']\n",
    "])\n",
    "y_test = np.array([\n",
    "    encode(labels, label2id, fallback='O', pad_token='O')\n",
    "    for labels in test_df['label_list']\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data (X, y): (34279, 40), (34279, 40)\n",
      "Shape of Validation Data (X_valid, y_valid): (3808, 40), (3808, 40)\n",
      "Shape of Test Data (X_test, y_test): (9520, 40), (9520, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data (X, y): {X.shape}, {y.shape}\")\n",
    "print(f\"Shape of Validation Data (X_valid, y_valid): {X_valid.shape}, {y_valid.shape}\")\n",
    "print(f\"Shape of Test Data (X_test, y_test): {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "X_valid = torch.from_numpy(X_valid)\n",
    "y_valid = torch.from_numpy(y_valid)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34279, 40])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self,X_tensor,y_tensor,lengths):\n",
    "        self.X = X_tensor\n",
    "        self.y = y_tensor\n",
    "        self.lengths = lengths\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    def __getitem__(self,idx):\n",
    "        return torch.tensor(self.X[idx],dtype= torch.long), \\\n",
    "                torch.tensor(self.y[idx], dtype = torch.long),\\\n",
    "                torch.tensor(self.lengths[idx], dtype = torch.long)\n",
    "#pack individual examples into a single batch\n",
    "def collate_fn(batch):  \n",
    "    tokens, tags,lengths= zip(*batch)\n",
    "    tokens = torch.stack(tokens)\n",
    "    tags = torch.stack(tags)\n",
    "    lengths = torch.stack(lengths)\n",
    "    return tokens, tags, lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.randint(10, (2, 2))\n",
    "y = torch.randint(5,(2,))\n",
    "length = [len(a) for a in example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import pdb\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = label2id['<PAD>']   # 0\n",
    "VOCAB_SIZE = vocab_size  # 30523\n",
    "TAGSET_SIZE = len(label2id)\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "#orignal length sequence:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTagger(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 tagset_size: int,\n",
    "                 embedding_dim: int = 200,\n",
    "                 hidden_dim: int = 128,\n",
    "                 num_layers: int = 1,\n",
    "                 dropout: float = 0.3,\n",
    "                 pad_idx: int = 0):  #pad_idx = vocab[\"<pad>\"]\n",
    "        super().__init__()  # python 3+ , if python 2+ then , super(BiLSTMTagger,self)\n",
    "        \n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,  ## hidden backward + hidden forward (h_tf+ h_tb)  # single then remove 2 , \n",
    "            \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # each time step we pass the output of LSTM to a fully connected layer \n",
    "        self.fc = nn.Linear(hidden_dim *2, tagset_size) # tagset_size = 10\n",
    "        self.softmax = nn.Softmax(dim=-1)  \n",
    "\n",
    "    def forward(self, x: torch.LongTensor,lengths: torch.LongTensor):\n",
    "        # exercice: put the shape of each layer\n",
    "        emb = self.embedding(x)  # (B,S,E_dim)\n",
    "        # Pack to let LSTM skip the padded tokens\n",
    "        # there are some sequences whose lengths are greater than 40(padding sequence)\n",
    "        lengths = torch.clamp(lengths, max = x.size(1))\n",
    "        \n",
    "        packed = pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False) #(T_total, Emb) (sum of actual sequence length)\n",
    "        # LSTM\n",
    "        packed_out,_ = self.lstm(packed)  # (T_total,Hidden_dimension*2(2H)) Hidden state for each time step  # Pytorch initialize the initial state to zero\n",
    "        lstm_out,_ = pad_packed_sequence(packed_out, batch_first=True, total_length=x.size(1))  # (B,S,2H) Ignore o, c, etc\n",
    "        \n",
    "        out = self.dropout(lstm_out)  #(B,S,2H)\n",
    "        logits = self.fc(out) #(B,S,C)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lengths_train = np.array([len(seq) for seq in train_df[\"tokens\"]])\n",
    "lengths_valid = np.array([len(seq) for seq in valid_df[\"tokens\"]])\n",
    "lengths_test = np.array([len(seq) for seq in test_df[\"tokens\"]])\n",
    "dataset_train = NERDataset(X,y,lengths_train)\n",
    "loader_train = DataLoader(dataset_train,\n",
    "                    batch_size = 32,\n",
    "                    shuffle = True,\n",
    "                    collate_fn = collate_fn,\n",
    "                    num_workers =0, # of CPU\n",
    "                    pin_memory = False)  # true if we use GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset \n",
    "\n",
    "dataset_valid = NERDataset(X_valid,y_valid, lengths_valid)\n",
    "loader_valid = DataLoader(dataset_valid,\n",
    "                    batch_size = 32,\n",
    "                    shuffle = True,\n",
    "                    collate_fn = collate_fn,\n",
    "                    num_workers =0, # of CPU\n",
    "                    pin_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset \n",
    "dataset_test = NERDataset(X_test,y_test, lengths_test)\n",
    "loader_test = DataLoader(dataset_test,\n",
    "                    batch_size = 32,\n",
    "                    shuffle = True,\n",
    "                    collate_fn = collate_fn,\n",
    "                    num_workers =0, # of CPU\n",
    "                    pin_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BiLSTMTagger(VOCAB_SIZE,TAGSET_SIZE).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index= PAD_IDX)\n",
    "#nn.CrossEntropyLoss—it expects raw logits and internally does a log_softmax followed by an NLL loss.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True,  True, False])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX = 0\n",
    "\n",
    "# Predicted labels (flattened from a batch of sequences)\n",
    "preds = torch.tensor([1, 2, 0, 3, 2, 0])\n",
    "\n",
    "# True labels\n",
    "labels = torch.tensor([1, 2, 0, 4, 2, 0])\n",
    "mask = labels != PAD_IDX\n",
    "# Output: tensor([True, True, False, True, True, False])\n",
    "preds == labels\n",
    "# Output: tensor([True, True, True, False, True, True])\n",
    "correct = (preds == labels) & mask\n",
    "# Output: tensor([ True,  True, False, False,  True, False])\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34279, 40])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for tmr: \n",
    "# ## write the accuracy function to put in the training loop\n",
    "# average accuracy \n",
    "def accuracy(pred,labels,pad_idx):\n",
    "    mask = labels != pad_idx\n",
    "    correct = (pred == labels) & mask\n",
    "    return correct.sum().item()/mask.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1754,  3225,   138,     7, 24721,     3,  3410,   110,    67,  1491,\n",
       "            6,  7972,  3287,    26,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EarlyStopping Class\n",
    "\n",
    "We can implement an `EarlyStopping` class to control the training phase if the validation loss stops improving.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **`patience`**  \n",
    "  Number of epochs to wait before stopping if no improvement.\n",
    "- **`delta`**  \n",
    "  Minimum change in the monitored quantity to qualify as an improvement.\n",
    "- **`best_score`**, **`best_model_state`**  \n",
    "  Track the best validation score and model state.\n",
    "\n",
    "### Methods\n",
    "\n",
    "- **`__call__(val_loss, model)`**  \n",
    "  Updates the early stopping logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self,epoch_limit = 5, improv_threshold = 0):\n",
    "        self.epoch_limit = epoch_limit\n",
    "        self.improv_threshold = improv_threshold  #minimum change\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "    # create our own callable to facilitate configuration\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()  #keep track of the model state (parameters(weights and biases))\n",
    "        elif score > self.best_score + self.improv_threshold:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.epoch_limit:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0  # reset counter to zero\n",
    "            \n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## example:\n",
    "\n",
    "# early_stop = EarlyStopping(epoch_limit = 4, improv_threshold = 1)\n",
    "\n",
    "# loss = 4\n",
    "# for i in range(4):\n",
    "#     loss += 0.5\n",
    "#     early_stop(loss)\n",
    "#     if early_stop.early_stop:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(epoch_limit=5, improv_threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "torch.manual_seed(42)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for batch_tokens, batch_tags, lengths in loader_train :  # tuple from the collate_fn function \n",
    "        batch_tokens = batch_tokens.to(device) #unecessary here since it is automatic\n",
    "        lengths = lengths.to(device)\n",
    "        batch_tags = batch_tags.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(batch_tokens,lengths)  # (B, S, C)  C = 10\n",
    "        # Flatten logits and targets for loss computation\n",
    "        logits = logits.reshape(-1, logits.size(-1))  # (B*S, C)\n",
    "        batch_tags = batch_tags.view(-1) #true value             # (B*S)\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, batch_tags)\n",
    "        # Regularization to generalize the model or to escape overfitting\n",
    "        l2_lambda = 0.001\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        loss = loss +l2_lambda*l2_norm\n",
    "            \n",
    "        # Backpropagation with anomaly detection\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            loss.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        \n",
    "         \n",
    "    #test on validation dataset\n",
    "    val_loss = 0.0\n",
    "    valid_accuracy = 0\n",
    "    num_batches = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for tokens, tags, lengths_valid in loader_valid:\n",
    "            tokens = tokens.to(device)\n",
    "            tags = tags.to(device)\n",
    "            lengths_valid = lengths_valid.to(device)\n",
    "            \n",
    "            output = model(tokens,lengths_valid)  #shape (B,S,C)\n",
    "            output_flat = output.view(-1,output.size(-1))  #(B*S,C)\n",
    "            tags_flat = tags.view(-1)  # shape (B*S,)\n",
    "            loss = criterion(output_flat,tags_flat)\n",
    "            val_loss += loss.item()\n",
    "            prediction_valid = torch.argmax(output,dim =-1)\n",
    "            valid_accuracy += accuracy(prediction_valid,tags,pad_idx = PAD_IDX)\n",
    "            num_batches += 1\n",
    "            \n",
    "    valid_accuracy = valid_accuracy/num_batches \n",
    "      \n",
    "    print(f\"Epoch {epoch+1} — Train_Loss: {train_loss:.4f}, Valid_Loss: {val_loss:.4f}, Accuracy_valid: {valid_accuracy:.4f}\")  \n",
    "    with open(\"training_log.txt\", \"a\") as f:\n",
    "        f.write(f\"Epoch {epoch+1} — Train_Loss: {train_loss:.4f}, Valid_Loss: {val_loss:.4f}, Accuracy_valid: {valid_accuracy:.4f}\\n\")\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "early_stopping.load_best_model(model)   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save learnable parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict()[\"embedding.weight\"], \"embedding_weight.pth\")\n",
    "# embedding_weight = torch.load(\"embedding_weight.pth\")\n",
    "# embedding_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #code that work:\n",
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# for epoch in range(1, NUM_EPOCHS + 1):\n",
    "#     # ——————— Training ———————\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     for batch_tokens, batch_tags, lengths in loader_train:\n",
    "#         batch_tokens = batch_tokens.to(device)\n",
    "#         batch_tags   = batch_tags.to(device)\n",
    "#         lengths      = lengths.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         # raw logits: (B, S, C)\n",
    "#         logits = model(batch_tokens, lengths)\n",
    "\n",
    "#         # flatten for loss: (B*S, C) and (B*S,)\n",
    "#         logits_flat = logits.view(-1, logits.size(-1))\n",
    "#         tags_flat   = batch_tags.view(-1)\n",
    "\n",
    "#         loss = criterion(logits_flat, tags_flat)\n",
    "#         with torch.autograd.set_detect_anomaly(True):\n",
    "#             loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = train_loss / len(loader_train)\n",
    "\n",
    "#     # ————— Validation —————\n",
    "#     model.eval()\n",
    "#     valid_loss = 0.0\n",
    "#     valid_acc  = 0.0\n",
    "#     n_batches  = 0\n",
    "\n",
    "#     with torch.inference_mode():\n",
    "#         for tokens, tags, lengths_valid in loader_valid:\n",
    "#             tokens = tokens.to(device)\n",
    "#             tags   = tags.to(device)\n",
    "#             lengths_valid = lengths_valid.to(device)\n",
    "\n",
    "#             # raw logits: (B, S, C)\n",
    "#             output = model(tokens, lengths_valid)\n",
    "\n",
    "#             # loss on flattened\n",
    "#             out_flat = output.view(-1, output.size(-1))\n",
    "#             tags_flat = tags.view(-1)\n",
    "#             loss = criterion(out_flat, tags_flat)\n",
    "#             valid_loss += loss.item()\n",
    "\n",
    "#             # predictions for accuracy\n",
    "#             preds = torch.argmax(output, dim=-1)       # (B, S)\n",
    "#             valid_acc += accuracy(preds.view(-1), tags_flat, pad_idx=PAD_IDX)\n",
    "#             n_batches += 1\n",
    "\n",
    "#     avg_valid_loss = valid_loss / n_batches\n",
    "#     avg_valid_acc  = valid_acc  / n_batches\n",
    "\n",
    "#     print(\n",
    "#         f\"Epoch {epoch}/{NUM_EPOCHS} — \"\n",
    "#         f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "#         f\"Valid Loss: {avg_valid_loss:.4f}, \"\n",
    "#         f\"Valid Acc: {avg_valid_acc:.4f}\"\n",
    "#     )\n",
    "\n",
    "#     # early stopping\n",
    "#     early_stopping(avg_valid_loss, model)\n",
    "#     if early_stopping.early_stop:\n",
    "#         print(\"Early stopping\")\n",
    "#         break\n",
    "\n",
    "# # load best model after training\n",
    "# early_stopping.load_best_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/m2ryk39s2slc67mc6y5xdxcm0000gn/T/ipykernel_42154/3044564666.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(logits)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([2.0, 1.0, 0.1])  # raw result from the pipeline\n",
    "probs = F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report as seqeval_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m298/298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo     0.8036    0.8564    0.8291      7491\n",
      "       B-gpe     0.9411    0.9037    0.9220      3166\n",
      "       B-org     0.7218    0.5719    0.6382      4006\n",
      "       B-per     0.8241    0.7663    0.7941      3350\n",
      "       B-tim     0.9009    0.8156    0.8562      3992\n",
      "       I-geo     0.7437    0.7974    0.7696      1441\n",
      "       I-org     0.8073    0.7057    0.7531      3259\n",
      "       I-per     0.8663    0.8020    0.8329      3450\n",
      "       I-tim     0.7883    0.6516    0.7135      1286\n",
      "           O     0.9909    0.9962    0.9936    349359\n",
      "\n",
      "    accuracy                         0.9781    380800\n",
      "   macro avg     0.8388    0.7867    0.8102    380800\n",
      "weighted avg     0.9773    0.9781    0.9775    380800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_ids_test = np.argmax(y_pred_test, axis=-1)   #compare the distribution of the output of softmax for a token-word (10 scores comparison)\n",
    "y_true_ids_test = y_test\n",
    "\n",
    "# Flatten and filter padding\n",
    "true_flat, pred_flat = [], []\n",
    "for i in range(len(y_true_ids_test)):\n",
    "    for true, pred in zip(y_true_ids_test[i], y_pred_ids_test[i]):\n",
    "            true_flat.append(id2label[true])\n",
    "            pred_flat.append(id2label[pred])\n",
    "\n",
    "# Report\n",
    "print(classification_report(true_flat, pred_flat, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_test_probs = y_pred_test.reshape(-1, y_pred_test.shape[-1])\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(label_size):\n",
    "    fpr[i], tpr[i], _ = roc_curve((y_test_flat == i).astype(int), y_pred_test_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(label_size):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {id2label[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Test Dataset')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all unique labels from your label map\n",
    "all_labels = sorted(list(set(true_flat + pred_flat)))\n",
    "\n",
    "cm = confusion_matrix(true_flat, pred_flat, labels=all_labels)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=all_labels, yticklabels=all_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(df, X, y_true_ids, y_pred_ids, index=0):\n",
    "    print(f\"\\nSentence: {' '.join(df.loc[index, 'tokens'])}\")\n",
    "    print(f\"{'Token':15} {'True':10} {'Predicted'}\")\n",
    "    print(\"-\" * 40)\n",
    "    for token, true, pred in zip(df.loc[index, 'tokens'], \n",
    "                                 [id2label[i] for i in y_true_ids[index]],\n",
    "                                 [id2label[i] for i in y_pred_ids[index]]):\n",
    "        print(f\"{token:15} {true:10} {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(test_df, X_test, y_true_ids_test, y_pred_ids_test, index=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pretrained embedding\n",
    "\n",
    "\n",
    "We encounter OOV(out-of-verb) problem  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use : GoogleNews-vectors-negative300.bin.gz\n",
    "Corpus that has 100 billion words. It uses the skip gram Word2Vec model. It uses negative sampling. Each word is represented by a 300 dimension vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings # to prevent displaying any warnings\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get the embedding vector for a word\n",
    "word = \"example\"  # Replace with the word you want\n",
    "if word in word2vec_model:\n",
    "    embedding_vector = word2vec_model[word]\n",
    "    print(f\"Embedding vector for '{word}':\\n{embedding_vector}\\n\")\n",
    "    print(f\"Dimension of the embedding vector:{len(embedding_vector)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(train_df[\"tokens\"], min_count = 1, vector_size = 100, window = 5, sg = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Families, of, soldiers, killed, in, the, conf...\n",
       "1        [Police, put, the, number, of, marchers, at, 1...\n",
       "2        [The, party, is, divided, over, Britain, 's, p...\n",
       "3        [Two, Germans, and, four, Nigerian, oil, worke...\n",
       "4        [The, German, firm, works, as, a, sub-contract...\n",
       "                               ...                        \n",
       "34274    [Indian, border, security, forces, are, accusi...\n",
       "34275    [Indian, officials, said, no, one, was, injure...\n",
       "34276    [Two, more, landed, in, fields, belonging, to,...\n",
       "34277    [They, say, not, all, of, the, rockets, explod...\n",
       "34278    [Indian, forces, said, they, responded, to, th...\n",
       "Name: tokens, Length: 34279, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip gram\n",
    "def Word2Vec(token):  #df[tokens].iloc[]\n",
    "    model = gensim.models.Word2Vec(train_df[\"tokens\"], min_count = 1, vector_size = 100, window = 5, sg = 1)\n",
    "    return model.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m298/298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.0831\n",
      "Test Loss: 0.0740, Accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Load the saved model\n",
    "# model = load_model('./models/ner_LSTM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_mask(sentence, model, word2id, label2id, id2label, MAX_LEN):\n",
    "    tokens = sentence.strip().split()\n",
    "    \n",
    "    def encode(tokens, vocab, pad_len=MAX_LEN, fallback='<UNK>', pad_token='<PAD>'):\n",
    "        fallback_id = vocab.get(fallback, list(vocab.values())[0])  \n",
    "        pad_id = vocab.get(pad_token, list(vocab.values())[0])    \n",
    "        ids = [vocab.get(tok, fallback_id) for tok in tokens]\n",
    "        return ids[:pad_len] + [pad_id] * max(0, pad_len - len(ids))\n",
    "    \n",
    "    encoded_sentence = encode(tokens, word2id, pad_len=MAX_LEN)\n",
    "    encoded_sentence = np.array([encoded_sentence])  \n",
    "    \n",
    "    # Predict using the model\n",
    "    y_pred = model.predict(encoded_sentence)\n",
    "    y_pred_ids = np.argmax(y_pred, axis=-1)[0] \n",
    "    \n",
    "    # Decode the sentence and labels\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    decoded_sentence = [id2word.get(word_id, '<UNK>') for word_id in encoded_sentence[0]]\n",
    "    decoded_labels = [id2label[label_id] for label_id in y_pred_ids]\n",
    "    \n",
    "    # Mask the entities in the sentence\n",
    "    masked_sentence = []\n",
    "    for token, label in zip(decoded_sentence, decoded_labels):\n",
    "        if token == '<PAD>':\n",
    "            continue\n",
    "        elif label == 'O':\n",
    "            masked_sentence.append(token)\n",
    "        else:\n",
    "            masked_sentence.append(label)\n",
    "    \n",
    "    # Print the original and masked sentence\n",
    "    print(\"Original Sentence:\")\n",
    "    print(\" \".join(tokens))\n",
    "    print(\"\\nMasked Sentence:\")\n",
    "    print(\" \".join(masked_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Original Sentence:\n",
      "Barack Obama was the president of the United States.\n",
      "\n",
      "Masked Sentence:\n",
      "B-per I-per was the president of the B-geo I-org\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "random_sentence = \"Barack Obama was the president of the United States.\"\n",
    "test_and_mask(random_sentence, model, word2id, label2id, id2label, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "random_sentence = \"On June 15, 2023, Dr. Emily Carter, a renowned physicist from Princeton University, gave a keynote speech at the Global Climate Summit in Geneva, Switzerland. She emphasized the urgent need for international collaboration to combat climate change. Representatives from over 50 countries, including Canada, Brazil, and India, attended the event. Microsoft and Tesla announced a joint venture to develop carbon-neutral technologies. Meanwhile, UN Secretary-General António Guterres praised the summit's progress in aligning with the Paris Agreement. The summit also featured contributions from scientists at MIT and Oxford University. Elon Musk participated virtually from California, showcasing Tesla’s latest solar innovations. A follow-up summit is scheduled for November 2024 in Tokyo, Japan. Attendees shared insights via the official Twitter hashtag #GCS2023. The event concluded with a ceremonial tree planting sponsored by Green Earth Foundation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "i = 1\n",
    "MAX_LEN = len(random_sentence)\n",
    "for i in range(0,MAX_LEN,40):\n",
    "    chunk = random_sentence[i:40+i]\n",
    "    string = ' '.join(chunk)\n",
    "    batches.append(string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Original Sentence:\n",
      "O n J u n e 1 5 , 2 0 2 3 , D r . E m i l y C a r t e r , a r e\n",
      "\n",
      "Masked Sentence:\n",
      "B-geo <UNK> <UNK> <UNK> <UNK> <UNK> B-tim I-tim , 2 <UNK> 2 3 , D <UNK> . <UNK> <UNK> I-per l <UNK> C a <UNK> <UNK> <UNK> I-per , a <UNK> <UNK>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[133]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m masked_sentence_ = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     original_sequence,masked_sentence = test_and_mask(sentence, model,word2id, label2id,id2label,\u001b[32m40\u001b[39m)\n\u001b[32m      4\u001b[39m     masked_sentence = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(masked_sentence)\n\u001b[32m      5\u001b[39m     masked_sentence_.append(masked_sentence)\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "masked_sentence_ = []\n",
    "for sentence in batches:\n",
    "    original_sequence,masked_sentence = test_and_mask(sentence, model,word2id, label2id,id2label,40)\n",
    "    masked_sentence = ' '.join(masked_sentence)\n",
    "    masked_sentence_.append(masked_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On',\n",
       " 'June',\n",
       " '15,',\n",
       " '2023,',\n",
       " 'Dr.',\n",
       " 'Emily',\n",
       " 'Carter,',\n",
       " 'a',\n",
       " 'renowned',\n",
       " 'physicist',\n",
       " 'from',\n",
       " 'Princeton',\n",
       " 'University,',\n",
       " 'gave',\n",
       " 'a',\n",
       " 'keynote',\n",
       " 'speech',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Global',\n",
       " 'Climate',\n",
       " 'Summit',\n",
       " 'in',\n",
       " 'Geneva,',\n",
       " 'Switzerland.',\n",
       " 'She',\n",
       " 'emphasized',\n",
       " 'the',\n",
       " 'urgent',\n",
       " 'need',\n",
       " 'for',\n",
       " 'international',\n",
       " 'collaboration',\n",
       " 'to',\n",
       " 'combat',\n",
       " 'climate',\n",
       " 'change.',\n",
       " 'Representatives',\n",
       " 'from',\n",
       " 'over',\n",
       " '50',\n",
       " 'countries,',\n",
       " 'including',\n",
       " 'Canada,',\n",
       " 'Brazil,',\n",
       " 'and',\n",
       " 'India,',\n",
       " 'attended',\n",
       " 'the',\n",
       " 'event.',\n",
       " 'Microsoft',\n",
       " 'and',\n",
       " 'Tesla',\n",
       " 'announced',\n",
       " 'a',\n",
       " 'joint',\n",
       " 'venture',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'carbon-neutral',\n",
       " 'technologies.',\n",
       " 'Meanwhile,',\n",
       " 'UN',\n",
       " 'Secretary-General',\n",
       " 'António',\n",
       " 'Guterres',\n",
       " 'praised',\n",
       " 'the',\n",
       " \"summit's\",\n",
       " 'progress',\n",
       " 'in',\n",
       " 'aligning',\n",
       " 'with',\n",
       " 'the',\n",
       " 'Paris',\n",
       " 'Agreement.',\n",
       " 'The',\n",
       " 'summit',\n",
       " 'also',\n",
       " 'featured',\n",
       " 'contributions',\n",
       " 'from',\n",
       " 'scientists',\n",
       " 'at',\n",
       " 'MIT',\n",
       " 'and',\n",
       " 'Oxford',\n",
       " 'University.',\n",
       " 'Elon',\n",
       " 'Musk',\n",
       " 'participated',\n",
       " 'virtually',\n",
       " 'from',\n",
       " 'California,',\n",
       " 'showcasing',\n",
       " 'Tesla’s',\n",
       " 'latest',\n",
       " 'solar',\n",
       " 'innovations.',\n",
       " 'A',\n",
       " 'follow-up',\n",
       " 'summit',\n",
       " 'is',\n",
       " 'scheduled',\n",
       " 'for',\n",
       " 'November',\n",
       " '2024',\n",
       " 'in',\n",
       " 'Tokyo,',\n",
       " 'Japan.',\n",
       " 'Attendees',\n",
       " 'shared',\n",
       " 'insights',\n",
       " 'via',\n",
       " 'the',\n",
       " 'official',\n",
       " 'Twitter',\n",
       " 'hashtag',\n",
       " '#GCS2023.',\n",
       " 'The',\n",
       " 'event',\n",
       " 'concluded',\n",
       " 'with',\n",
       " 'a',\n",
       " 'ceremonial',\n",
       " 'tree',\n",
       " 'planting',\n",
       " 'sponsored',\n",
       " 'by',\n",
       " 'Green',\n",
       " 'Earth',\n",
       " 'Foundation.']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
